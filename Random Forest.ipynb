{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 646,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "from pandas.api.types import CategoricalDtype\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.tree import export_graphviz \n",
    "from sklearn.model_selection import KFold\n",
    "from pydot import pydot\n",
    "#cloned into https://github.com/erocarrera/pydot\n",
    "#from pydot import dot_parser\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Which types of companies are one time donors? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 695,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['pounds', 'state_California', 'state_New York', 'state_Underdeveloped',\n",
       "       'month_1', 'month_10', 'month_11', 'month_12', 'month_2', 'month_3',\n",
       "       'month_4', 'month_5', 'month_6', 'month_7', 'month_8', 'month_9',\n",
       "       'year_2017', 'year_2018', 'weekday_Friday', 'weekday_Monday',\n",
       "       'weekday_Saturday', 'weekday_Thursday', 'weekday_Tuesday',\n",
       "       'weekday_Wednesday', 'size_10.0', 'size_1000.0', 'size_10000.0',\n",
       "       'size_10001.0', 'size_200.0', 'size_50.0', 'size_500.0', 'size_5000.0',\n",
       "       'type_applied', 'type_bus', 'type_comm', 'type_edu-health', 'type_fin',\n",
       "       'type_food', 'type_other', 'type_sale', 'type_soft', 'type_web',\n",
       "       'company', 'date'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 695,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "food.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 865,
   "metadata": {},
   "outputs": [],
   "source": [
    "food = pd.read_csv(\"no_ell_outliers\")\n",
    "food = food.drop([\"Unnamed: 0\", \"Unnamed: 0.1\", \"Id\", \"id\", \"number\", \"street\", \"city\", \n",
    "                  \"zip\", \"lat\", \"lon\", \"pickup\", \"planned\", \"month\", \"day\", \"year\", \"weekday\"], axis = 1)\n",
    "company = pd.read_csv(\"company_full.csv\")\n",
    "#company = company.drop(\"company\", axis = 1)\n",
    "company[\"multi_donor\"] = 1 - company[\"one_donation\"]\n",
    "company = company.drop(\"one_donation\", axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 866,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['food', 'other', 'comm', 'fin', 'soft', 'bus', 'edu-health',\n",
       "       'applied', 'web', 'sale'], dtype=object)"
      ]
     },
     "execution_count": 866,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "food[\"type\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining company types based on proportion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 867,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_food = company[company[\"type_food\"] == 1][\"multi_donor\"]\n",
    "company_other = company[company[\"type_other\"] == 1][\"multi_donor\"]\n",
    "company_comm = company[company[\"type_comm\"] == 1][\"multi_donor\"]\n",
    "company_fin = company[company[\"type_fin\"] == 1][\"multi_donor\"]\n",
    "company_soft = company[company[\"type_soft\"] == 1][\"multi_donor\"]\n",
    "company_bus = company[company[\"type_bus\"] == 1][\"multi_donor\"]\n",
    "company_eh = company[company[\"type_edu-health\"] == 1][\"multi_donor\"]\n",
    "company_applied = company[company[\"type_applied\"] == 1][\"multi_donor\"]\n",
    "company_web = company[company[\"type_web\"] == 1][\"multi_donor\"]\n",
    "company_sale = company[company[\"type_sale\"] == 1][\"multi_donor\"]\n",
    "dists_name = [\"Food\", \"Other\", \"Communication\", \"Finance\", \"Software\", \n",
    "             \"Business\", \"Education-Health\", \"Applied\", \"Web\", \"Sale\"]\n",
    "dists = [company_food, company_other, company_comm, company_fin, company_soft,\n",
    "        company_bus, company_eh, company_applied, company_web, company_sale]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 868,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "props = []\n",
    "for i in range(len(dists)):\n",
    "    dist = [sum(dists[i].sample(1000, replace = True))/1000 for j in range(1000)]\n",
    "    props.append(sum(dist)/1000)\n",
    "props = np.array(props)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 869,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company Type and Proportions:\n",
      "food 0.628778\n",
      "other 0.64721\n",
      "comm 0.577347\n",
      "fin 0.703347\n",
      "soft 0.812676\n",
      "bus 0.710036\n",
      "edu-health 0.571004\n",
      "applied 0.545552\n",
      "web 0.578562\n",
      "sale 0.646961\n"
     ]
    }
   ],
   "source": [
    "print(\"Company Type and Proportions:\")\n",
    "for i in range(len(props)):\n",
    "    print(food[\"type\"].unique()[i], props[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 870,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Food and Other: 0.20\n",
      "Food and Communication: 0.01\n",
      "Food and Finance: 0.00\n",
      "Food and Software: 0.00\n",
      "Food and Business: 0.00\n",
      "Food and Education-Health: 0.00\n",
      "Food and Applied: 0.00\n",
      "Food and Web: 0.01\n",
      "Food and Sale: 0.20\n"
     ]
    }
   ],
   "source": [
    "print()\n",
    "for i in range(1, len(dists)): \n",
    "    n1 = 1000\n",
    "    n2 = 1000\n",
    "    p1 = props[0]\n",
    "    p2 = props[i]\n",
    "    p = (n1 * p1 + n2 * p2)/(n1 + n2)\n",
    "    z = (p1 - p2)/(p * (1 - p) * (1/n1 + 1/n2))**0.5\n",
    "    print(\"Food and \" + dists_name[i] + ': {0:0.2f}'.format(\n",
    "     1 - norm.cdf(abs(z))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 871,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Other and Communication: 0.00\n",
      "Other and Finance: 0.00\n",
      "Other and Software: 0.00\n",
      "Other and Business: 0.00\n",
      "Other and Education-Health: 0.00\n",
      "Other and Applied: 0.00\n",
      "Other and Web: 0.00\n",
      "Other and Sale: 0.50\n"
     ]
    }
   ],
   "source": [
    "for i in range(2, len(dists)): \n",
    "    n1 = 1000\n",
    "    n2 = 1000\n",
    "    p1 = props[1]\n",
    "    p2 = props[i]\n",
    "    p = (n1 * p1 + n2 * p2)/(n1 + n2)\n",
    "    z = (p1 - p2)/(p * (1 - p) * (1/n1 + 1/n2))**0.5\n",
    "    print(\"Other and \" + dists_name[i] + ': {0:0.2f}'.format(\n",
    "     1 - norm.cdf(abs(z))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 872,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Communication and Finance: 0.00\n",
      "Communication and Software: 0.00\n",
      "Communication and Business: 0.00\n",
      "Communication and Education-Health: 0.39\n",
      "Communication and Applied: 0.08\n",
      "Communication and Web: 0.48\n",
      "Communication and Sale: 0.00\n"
     ]
    }
   ],
   "source": [
    "for i in range(3, len(dists)): \n",
    "    n1 = 1000\n",
    "    n2 = 1000\n",
    "    p1 = props[2]\n",
    "    p2 = props[i]\n",
    "    p = (n1 * p1 + n2 * p2)/(n1 + n2)\n",
    "    z = (p1 - p2)/(p * (1 - p) * (1/n1 + 1/n2))**0.5\n",
    "    print(\"Communication and \" + dists_name[i] + ': {0:0.2f}'.format(\n",
    "      1 - norm.cdf(abs(z))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 873,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finance and Software: 0.00\n",
      "Finance and Business: 0.37\n",
      "Finance and Education-Health: 0.00\n",
      "Finance and Applied: 0.00\n",
      "Finance and Web: 0.00\n",
      "Finance and Sale: 0.00\n"
     ]
    }
   ],
   "source": [
    "for i in range(4, len(dists)): \n",
    "    n1 = 1000\n",
    "    n2 = 1000\n",
    "    p1 = props[3]\n",
    "    p2 = props[i]\n",
    "    p = (n1 * p1 + n2 * p2)/(n1 + n2)\n",
    "    z = (p1 - p2)/(p * (1 - p) * (1/n1 + 1/n2))**0.5\n",
    "    print(\"Finance and \" + dists_name[i] + ': {0:0.2f}'.format(\n",
    "      1 - norm.cdf(abs(z))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 874,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Software and Business: 0.00\n",
      "Software and Education-Health: 0.00\n",
      "Software and Applied: 0.00\n",
      "Software and Web: 0.00\n",
      "Software and Sale: 0.00\n"
     ]
    }
   ],
   "source": [
    "for i in range(5, len(dists)): \n",
    "    n1 = 1000\n",
    "    n2 = 1000\n",
    "    p1 = props[4]\n",
    "    p2 = props[i]\n",
    "    p = (n1 * p1 + n2 * p2)/(n1 + n2)\n",
    "    z = (p1 - p2)/(p * (1 - p) * (1/n1 + 1/n2))**0.5\n",
    "    print(\"Software and \" + dists_name[i] + ': {0:0.2f}'.format(\n",
    "      1 - norm.cdf(abs(z))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 875,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Business and Education-Health: 0.00\n",
      "Business and Applied: 0.00\n",
      "Business and Web: 0.00\n",
      "Business and Sale: 0.00\n"
     ]
    }
   ],
   "source": [
    "for i in range(6, len(dists)): \n",
    "    n1 = 1000\n",
    "    n2 = 1000\n",
    "    p1 = props[5]\n",
    "    p2 = props[i]\n",
    "    p = (n1 * p1 + n2 * p2)/(n1 + n2)\n",
    "    z = (p1 - p2)/(p * (1 - p) * (1/n1 + 1/n2))**0.5\n",
    "    print(\"Business and \" + dists_name[i] + ': {0:0.2f}'.format(\n",
    "      1 - norm.cdf(abs(z))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 876,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Education-Health and Applied: 0.13\n",
      "Education-Health and Web: 0.37\n",
      "Education-Health and Sale: 0.00\n"
     ]
    }
   ],
   "source": [
    "for i in range(7, len(dists)): \n",
    "    n1 = 1000\n",
    "    n2 = 1000\n",
    "    p1 = props[6]\n",
    "    p2 = props[i]\n",
    "    p = (n1 * p1 + n2 * p2)/(n1 + n2)\n",
    "    z = (p1 - p2)/(p * (1 - p) * (1/n1 + 1/n2))**0.5\n",
    "    print(\"Education-Health and \" + dists_name[i] + ': {0:0.2f}'.format(\n",
    "      1 - norm.cdf(abs(z))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 877,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied and Web: 0.07\n",
      "Applied and Sale: 0.00\n"
     ]
    }
   ],
   "source": [
    "for i in range(8, len(dists)): \n",
    "    n1 = 1000\n",
    "    n2 = 1000\n",
    "    p1 = props[7]\n",
    "    p2 = props[i]\n",
    "    p = (n1 * p1 + n2 * p2)/(n1 + n2)\n",
    "    z = (p1 - p2)/(p * (1 - p) * (1/n1 + 1/n2))**0.5\n",
    "    print(\"Applied and \" + dists_name[i] + ': {0:0.2f}'.format(\n",
    "      1 - norm.cdf(abs(z))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 878,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Web and Sale: 0.00\n"
     ]
    }
   ],
   "source": [
    "for i in range(9, len(dists)): \n",
    "    n1 = 1000\n",
    "    n2 = 1000\n",
    "    p1 = props[8]\n",
    "    p2 = props[i]\n",
    "    p = (n1 * p1 + n2 * p2)/(n1 + n2)\n",
    "    z = (p1 - p2)/(p * (1 - p) * (1/n1 + 1/n2))**0.5\n",
    "    print(\"Web and \" + dists_name[i] + ': {0:0.2f}'.format(\n",
    "      1 - norm.cdf(abs(z))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 879,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['company', 'size_10.0', 'size_1000.0', 'size_10000.0', 'size_10001.0',\n",
       "       'size_200.0', 'size_50.0', 'size_500.0', 'size_5000.0',\n",
       "       'state_California', 'state_New York', 'state_underdeveloped',\n",
       "       'type_applied', 'type_bus', 'type_comm', 'type_edu-health', 'type_fin',\n",
       "       'type_food', 'type_other', 'type_sale', 'type_soft', 'type_web',\n",
       "       'multi_donor'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 879,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "company.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 880,
   "metadata": {},
   "outputs": [],
   "source": [
    "company[\"food_other_sale\"] = company.iloc[:, [17, 18, 19]].sum(axis = 1)\n",
    "company[\"comm_edu/health_web\"] = company.iloc[:, [14, 15, 21]].sum(axis = 1)\n",
    "company[\"fin_bus\"] = company.iloc[:, [13, 16]].sum(axis = 1)\n",
    "company = company.drop([ \"type_food\", \"type_other\", \"type_sale\", \"type_comm\", \n",
    "                       \"type_edu-health\", \"type_web\", \"type_fin\", \"type_bus\"], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining company sizes based on proportions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 881,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['company', 'size_10.0', 'size_1000.0', 'size_10000.0', 'size_10001.0',\n",
       "       'size_200.0', 'size_50.0', 'size_500.0', 'size_5000.0',\n",
       "       'state_California', 'state_New York', 'state_underdeveloped',\n",
       "       'type_applied', 'type_soft', 'multi_donor', 'food_other_sale',\n",
       "       'comm_edu/health_web', 'fin_bus'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 881,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "company.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 882,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_10 = company[company[\"size_10.0\"] == 1][\"multi_donor\"]\n",
    "company_50 = company[company[\"size_50.0\"] == 1][\"multi_donor\"]\n",
    "company_200 = company[company[\"size_200.0\"] == 1][\"multi_donor\"]\n",
    "company_500 = company[company[\"size_500.0\"] == 1][\"multi_donor\"]\n",
    "company_1000 = company[company[\"size_1000.0\"] == 1][\"multi_donor\"]\n",
    "company_5000 = company[company[\"size_5000.0\"] == 1][\"multi_donor\"]\n",
    "company_10000 = company[company[\"size_10000.0\"] == 1][\"multi_donor\"]\n",
    "company_10001 = company[company[\"size_10001.0\"] == 1][\"multi_donor\"]\n",
    "dists_name = [\"10\", \"50\", \"200\", \"500\", \"1000\", \n",
    "             \"5000\", \"10000\", \"10001\"]\n",
    "dists = [company_10, company_50, company_200, company_500, company_1000,\n",
    "        company_5000, company_10000, company_10001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 883,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "props = []\n",
    "for i in range(len(dists)):\n",
    "    dist = [sum(dists[i].sample(1000, replace = True))/1000 for j in range(1000)]\n",
    "    props.append(sum(dist)/1000)\n",
    "props = np.array(props)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 884,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company Size and Proportions:\n",
      "10:  0.583443\n",
      "50:  0.593456\n",
      "200:  0.661663\n",
      "500:  0.644822\n",
      "1000:  0.899745\n",
      "5000:  0.590446\n",
      "10000:  0.499443\n",
      "10001:  0.443786\n"
     ]
    }
   ],
   "source": [
    "print(\"Company Size and Proportions:\")\n",
    "for i in range(len(props)):\n",
    "    print(dists_name[i] + \": \", props[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 885,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 and 50: 0.32\n",
      "10 and 200: 0.00\n",
      "10 and 500: 0.00\n",
      "10 and 1000: 0.00\n",
      "10 and 5000: 0.38\n",
      "10 and 10000: 0.00\n",
      "10 and 10001: 0.00\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, len(dists)): \n",
    "    n1 = 1000\n",
    "    n2 = 1000\n",
    "    p1 = props[0]\n",
    "    p2 = props[i]\n",
    "    p = (n1 * p1 + n2 * p2)/(n1 + n2)\n",
    "    z = (p1 - p2)/(p * (1 - p) * (1/n1 + 1/n2))**0.5\n",
    "    print(\"10 and \" + dists_name[i] + ': {0:0.2f}'.format(\n",
    "     1 - norm.cdf(abs(z))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 886,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 and 200: 0.00\n",
      "50 and 500: 0.01\n",
      "50 and 1000: 0.00\n",
      "50 and 5000: 0.45\n",
      "50 and 10000: 0.00\n",
      "50 and 10001: 0.00\n"
     ]
    }
   ],
   "source": [
    "for i in range(2, len(dists)): \n",
    "    n1 = 1000\n",
    "    n2 = 1000\n",
    "    p1 = props[1]\n",
    "    p2 = props[i]\n",
    "    p = (n1 * p1 + n2 * p2)/(n1 + n2)\n",
    "    z = (p1 - p2)/(p * (1 - p) * (1/n1 + 1/n2))**0.5\n",
    "    print(\"50 and \" + dists_name[i] + ': {0:0.2f}'.format(\n",
    "     1 - norm.cdf(abs(z))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 887,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 and 500: 0.21\n",
      "200 and 1000: 0.00\n",
      "200 and 5000: 0.00\n",
      "200 and 10000: 0.00\n",
      "200 and 10001: 0.00\n"
     ]
    }
   ],
   "source": [
    "for i in range(3, len(dists)): \n",
    "    n1 = 1000\n",
    "    n2 = 1000\n",
    "    p1 = props[2]\n",
    "    p2 = props[i]\n",
    "    p = (n1 * p1 + n2 * p2)/(n1 + n2)\n",
    "    z = (p1 - p2)/(p * (1 - p) * (1/n1 + 1/n2))**0.5\n",
    "    print(\"200 and \" + dists_name[i] + ': {0:0.2f}'.format(\n",
    "     1 - norm.cdf(abs(z))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 888,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 and 1000: 0.00\n",
      "500 and 5000: 0.01\n",
      "500 and 10000: 0.00\n",
      "500 and 10001: 0.00\n"
     ]
    }
   ],
   "source": [
    "for i in range(4, len(dists)): \n",
    "    n1 = 1000\n",
    "    n2 = 1000\n",
    "    p1 = props[3]\n",
    "    p2 = props[i]\n",
    "    p = (n1 * p1 + n2 * p2)/(n1 + n2)\n",
    "    z = (p1 - p2)/(p * (1 - p) * (1/n1 + 1/n2))**0.5\n",
    "    print(\"500 and \" + dists_name[i] + ': {0:0.2f}'.format(\n",
    "     1 - norm.cdf(abs(z))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 889,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 and 5000: 0.00\n",
      "1000 and 10000: 0.00\n",
      "1000 and 10001: 0.00\n"
     ]
    }
   ],
   "source": [
    "for i in range(5, len(dists)): \n",
    "    n1 = 1000\n",
    "    n2 = 1000\n",
    "    p1 = props[4]\n",
    "    p2 = props[i]\n",
    "    p = (n1 * p1 + n2 * p2)/(n1 + n2)\n",
    "    z = (p1 - p2)/(p * (1 - p) * (1/n1 + 1/n2))**0.5\n",
    "    print(\"1000 and \" + dists_name[i] + ': {0:0.2f}'.format(\n",
    "     1 - norm.cdf(abs(z))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 890,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000 and 10000: 0.00\n",
      "5000 and 10001: 0.00\n"
     ]
    }
   ],
   "source": [
    "for i in range(6, len(dists)): \n",
    "    n1 = 1000\n",
    "    n2 = 1000\n",
    "    p1 = props[5]\n",
    "    p2 = props[i]\n",
    "    p = (n1 * p1 + n2 * p2)/(n1 + n2)\n",
    "    z = (p1 - p2)/(p * (1 - p) * (1/n1 + 1/n2))**0.5\n",
    "    print(\"5000 and \" + dists_name[i] + ': {0:0.2f}'.format(\n",
    "     1 - norm.cdf(abs(z))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 891,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 and 10001: 0.01\n"
     ]
    }
   ],
   "source": [
    "for i in range(7, len(dists)): \n",
    "    n1 = 1000\n",
    "    n2 = 1000\n",
    "    p1 = props[6]\n",
    "    p2 = props[i]\n",
    "    p = (n1 * p1 + n2 * p2)/(n1 + n2)\n",
    "    z = (p1 - p2)/(p * (1 - p) * (1/n1 + 1/n2))**0.5\n",
    "    print(\"10000 and \" + dists_name[i] + ': {0:0.2f}'.format(\n",
    "     1 - norm.cdf(abs(z))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 892,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['company', 'size_10.0', 'size_1000.0', 'size_10000.0', 'size_10001.0',\n",
       "       'size_200.0', 'size_50.0', 'size_500.0', 'size_5000.0',\n",
       "       'state_California', 'state_New York', 'state_underdeveloped',\n",
       "       'type_applied', 'type_soft', 'multi_donor', 'food_other_sale',\n",
       "       'comm_edu/health_web', 'fin_bus'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 892,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "company.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 893,
   "metadata": {},
   "outputs": [],
   "source": [
    "company[\"size_10/50\"] = company.iloc[:, [1, 6]].sum(axis = 1)\n",
    "company[\"size_200/500\"] = company.iloc[:, [5, 7]].sum(axis = 1)\n",
    "company = company.drop([\"size_10.0\", \"size_50.0\", \"size_200.0\", \"size_500.0\"], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking at whether a company would be a one time donor before their first donation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 894,
   "metadata": {},
   "outputs": [],
   "source": [
    "#features = food.drop([\"Unnamed: 0\", \"Id\", \"date\", \"number\", \"street\", \"city\", \"company\", \"zip\", \"lat\", \"lon\", \"pickup\", \"planned\", \"day\", \"year\"], axis = 1)\n",
    "#features.loc[(features[\"state\"] != \"California\") & (features[\"state\"] != \"New York\"), \"state\"] = \"underdeveloped\"\n",
    "features = company.drop([\"multi_donor\", \"company\"], axis = 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 895,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['company', 'size_1000.0', 'size_10000.0', 'size_10001.0', 'size_5000.0',\n",
       "       'state_California', 'state_New York', 'state_underdeveloped',\n",
       "       'type_applied', 'type_soft', 'multi_donor', 'food_other_sale',\n",
       "       'comm_edu/health_web', 'fin_bus', 'size_10/50', 'size_200/500'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 895,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "company.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 896,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(242, 14)"
      ]
     },
     "execution_count": 896,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 897,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = company[\"multi_donor\"]\n",
    "#features = pd.get_dummies(features)\n",
    "feature_list = list(features.columns)\n",
    "features = np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 898,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, test_features, train_labels, test_labels = train_test_split(features, y, test_size = 0.25, random_state = 23156)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 899,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators = 1000, random_state = 12356)\n",
    "rf.fit(train_features, train_labels);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 900,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 900,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = rf.predict(test_features)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 901,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6885245901639344"
      ]
     },
     "execution_count": 901,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(test_labels == predictions)/len(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 902,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable: state_underdeveloped Importance: 0.11\n",
      "Variable: size_200/500         Importance: 0.1\n",
      "Variable: state_New York       Importance: 0.09\n",
      "Variable: size_10/50           Importance: 0.09\n",
      "Variable: state_California     Importance: 0.08\n",
      "Variable: comm_edu/health_web  Importance: 0.08\n",
      "Variable: size_1000.0          Importance: 0.07\n",
      "Variable: fin_bus              Importance: 0.07\n",
      "Variable: size_5000.0          Importance: 0.06\n",
      "Variable: type_applied         Importance: 0.06\n",
      "Variable: food_other_sale      Importance: 0.06\n",
      "Variable: size_10000.0         Importance: 0.04\n",
      "Variable: size_10001.0         Importance: 0.04\n",
      "Variable: type_soft            Importance: 0.04\n"
     ]
    }
   ],
   "source": [
    "importances = list(rf.feature_importances_)\n",
    "feature_importances = [(feature, round(importance, 2)) for feature, importance in zip(feature_list, importances)]\n",
    "feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n",
    "[print('Variable: {:20} Importance: {}'.format(*pair)) for pair in feature_importances];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tree = rf.estimators_[5]\n",
    "#export_graphviz(tree, out_file = 'tree.dot', feature_names = feature_list, rounded = True, precision = 1)\n",
    "#(graph, ) = graph_from_dot_file('tree.dot')\n",
    "#graph.write_png('tree.png')\n",
    "#dot_parser.parse_dot_data(\"tree.dot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "max_features = [\"auto\", \"sqrt\"]\n",
    "max_depth = [int(x) for x in np.linspace(start = 3, stop = 60, num = 20)] \n",
    "#max_depth.append(None)\n",
    "min_samples_split = [int(x) for x in np.linspace(start = 2, stop = 10, num = 10)]\n",
    "min_samples_leaf = [int(x) for x in np.linspace(start = 1, stop = 5, num = 5)]\n",
    "bootstrap = [True, False] \n",
    "\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 903,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 50 candidates, totalling 500 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-903-292c7bfd6cc9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m                               \u001b[0mn_iter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m6819\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                               n_jobs = -1)\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mrf_random\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\jordan fan\\anaconda3\\envs\\toxic\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    637\u001b[0m                                   error_score=self.error_score)\n\u001b[0;32m    638\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[1;32m--> 639\u001b[1;33m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    640\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m         \u001b[1;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jordan fan\\anaconda3\\envs\\toxic\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    787\u001b[0m                 \u001b[1;31m# consumption.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 789\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    790\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jordan fan\\anaconda3\\envs\\toxic\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    697\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    698\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 699\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    700\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jordan fan\\anaconda3\\envs\\toxic\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    637\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 638\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    639\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mready\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    640\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jordan fan\\anaconda3\\envs\\toxic\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    633\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 635\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    637\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jordan fan\\anaconda3\\envs\\toxic\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    550\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 551\u001b[1;33m                 \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    552\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    553\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jordan fan\\anaconda3\\envs\\toxic\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    293\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 295\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    297\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid,\n",
    "                              n_iter = 50, cv = 10, verbose = 2, random_state = 6819,\n",
    "                              n_jobs = -1)\n",
    "rf_random.fit(train_features, train_labels)\n",
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 904,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7213114754098361"
      ]
     },
     "execution_count": 904,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(bootstrap = True,\n",
    "                            max_depth = 3,\n",
    "                            max_features = \"auto\",\n",
    "                            min_samples_leaf = 1,\n",
    "                            min_samples_split = 8,\n",
    "                            n_estimators = 1000,\n",
    "                            random_state = 12356)\n",
    "rf.fit(train_features, train_labels);\n",
    "sum(rf.predict(test_features) == test_labels)/len(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 905,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable: state_underdeveloped Importance: 0.21\n",
      "Variable: size_1000.0          Importance: 0.14\n",
      "Variable: size_10/50           Importance: 0.08\n",
      "Variable: state_California     Importance: 0.07\n",
      "Variable: state_New York       Importance: 0.07\n",
      "Variable: type_applied         Importance: 0.06\n",
      "Variable: comm_edu/health_web  Importance: 0.06\n",
      "Variable: fin_bus              Importance: 0.06\n",
      "Variable: size_200/500         Importance: 0.06\n",
      "Variable: size_5000.0          Importance: 0.05\n",
      "Variable: size_10001.0         Importance: 0.04\n",
      "Variable: type_soft            Importance: 0.04\n",
      "Variable: food_other_sale      Importance: 0.04\n",
      "Variable: size_10000.0         Importance: 0.03\n"
     ]
    }
   ],
   "source": [
    "importances = list(rf.feature_importances_)\n",
    "feature_importances = [(feature, round(importance, 2)) for feature, importance in zip(feature_list, importances)]\n",
    "feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n",
    "[print('Variable: {:20} Importance: {}'.format(*pair)) for pair in feature_importances];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 908,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision Score: 0.73\n",
      "Recall Score: 0.95\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "precision_accuracy = precision_score(test_labels, rf.predict(test_features))\n",
    "recall_accuracy = recall_score(test_labels, rf.predict(test_features))\n",
    "\n",
    "print('Precision Score: {0:0.2f}'.format(\n",
    "      precision_accuracy))\n",
    "print('Recall Score: {0:0.2f}'.format(\n",
    "      recall_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 909,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = rf.predict(test_features)\n",
    "predicted_one_time = [i for i in range(len(preds)) if preds[i] == 1]\n",
    "predicted_multi_time = [i for i in range(len(preds)) if preds[i] == 0]\n",
    "true_one_time = [i for i in range(len(test_labels)) if np.array(test_labels)[i] == 1]\n",
    "true_multi_time = [i for i in range(len(test_labels)) if np.array(test_labels)[i] == 0]\n",
    "true_positives = len(np.intersect1d(predicted_one_time, true_one_time))\n",
    "false_positives = len(np.intersect1d(predicted_one_time, true_multi_time))\n",
    "true_negatives = len(np.intersect1d(predicted_multi_time, true_multi_time))\n",
    "false_negatives = len(np.intersect1d(predicted_multi_time, true_one_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 910,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = true_positives/(true_positives + false_positives)\n",
    "recall = true_positives/(true_positives + false_negatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 911,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7272727272727273 0.9523809523809523\n"
     ]
    }
   ],
   "source": [
    "print(precision, recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 721,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 721,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking at whether a company would be a one time donor after donation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 819,
   "metadata": {},
   "outputs": [],
   "source": [
    "food[\"date\"] = pd.to_datetime(food[\"date\"])\n",
    "food[\"size\"] = food[\"size\"].astype(\"str\")\n",
    "company2_num_donation = food.groupby(\"company\")[\"company\"].count()\n",
    "company2_one_donation = (company2_num_donation == 1).astype(\"int\")\n",
    "company2_size = food.groupby(\"company\")[\"size\"].first()\n",
    "company2_type = food.groupby(\"company\")[\"type\"].first()\n",
    "company2_state = food.groupby(\"company\")[\"state\"].first()\n",
    "company2_last_donation_weeks = (np.max(food[\"date\"]) - food.groupby(\"company\")[\"date\"].agg(np.max)).apply(lambda x: x.days)//7\n",
    "#company2_last_donation = food[food.groupby(\"company\").date.transform(\"max\") == food[\"date\"]].groupby(\"company\").first()[\"pounds\"]\n",
    "company2 = pd.DataFrame({\"multi_donor\": 1 - company2_one_donation,\n",
    "                       \"size\": company2_size, \"type\": company2_type,\n",
    "                       \"state\": company2_state, \n",
    "#                        \"last_donation\": company2_last_donation,\n",
    "                        \"last_donation_weeks\": company2_last_donation_weeks,\n",
    "                       })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 820,
   "metadata": {},
   "outputs": [],
   "source": [
    "company2 = pd.get_dummies(company2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 821,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['last_donation_weeks', 'multi_donor', 'size_10.0', 'size_1000.0',\n",
       "       'size_10000.0', 'size_10001.0', 'size_200.0', 'size_50.0', 'size_500.0',\n",
       "       'size_5000.0', 'state_California', 'state_New York',\n",
       "       'state_Underdeveloped', 'type_applied', 'type_bus', 'type_comm',\n",
       "       'type_edu-health', 'type_fin', 'type_food', 'type_other', 'type_sale',\n",
       "       'type_soft', 'type_web'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 821,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "company2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 839,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "positional indexers are out-of-bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-839-1b370e9a8805>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcompany2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"food_other_sale\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompany2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m19\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m21\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mcompany2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"comm_edu/health_web\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompany2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m17\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m23\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mcompany2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"fin_bus\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompany2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m18\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m15\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m company2 = company2.drop([ \"type_food\", \"type_other\", \"type_sale\", \"type_comm\", \n\u001b[0;32m      5\u001b[0m                        \"type_edu-health\", \"type_web\", \"type_fin\", \"type_bus\"], axis = 1)\n",
      "\u001b[1;32mc:\\users\\jordan fan\\anaconda3\\envs\\toxic\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1365\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mKeyError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1366\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1367\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1368\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1369\u001b[0m             \u001b[1;31m# we by definition only have the 0th axis\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jordan fan\\anaconda3\\envs\\toxic\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_tuple\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m   1735\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_getitem_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1736\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1737\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_has_valid_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1738\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1739\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_lowerdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jordan fan\\anaconda3\\envs\\toxic\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_has_valid_tuple\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    202\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mIndexingError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Too many indexers'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 204\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_has_valid_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    205\u001b[0m                 raise ValueError(\"Location based indexing can only have \"\n\u001b[0;32m    206\u001b[0m                                  \u001b[1;34m\"[{types}] types\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jordan fan\\anaconda3\\envs\\toxic\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_has_valid_type\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1672\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_valid_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1673\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mis_list_like_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1674\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_valid_list_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1675\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1676\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jordan fan\\anaconda3\\envs\\toxic\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_is_valid_list_like\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1729\u001b[0m         if (hasattr(arr, '__len__') and len(arr) and\n\u001b[0;32m   1730\u001b[0m                 (arr.max() >= l or arr.min() < -l)):\n\u001b[1;32m-> 1731\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"positional indexers are out-of-bounds\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1732\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1733\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: positional indexers are out-of-bounds"
     ]
    }
   ],
   "source": [
    "company2[\"food_other_sale\"] = company2.iloc[:, [19, 20, 21]].sum(axis = 1)\n",
    "company2[\"comm_edu/health_web\"] = company2.iloc[:, [16, 17, 23]].sum(axis = 1)\n",
    "company2[\"fin_bus\"] = company2.iloc[:, [18, 15]].sum(axis = 1)\n",
    "company2 = company2.drop([ \"type_food\", \"type_other\", \"type_sale\", \"type_comm\", \n",
    "                       \"type_edu-health\", \"type_web\", \"type_fin\", \"type_bus\"], axis = 1)\n",
    "#company2[\"size_10/50\"] = company2.iloc[:, [3, 8]].sum(axis = 1)\n",
    "#company2[\"size_200/500\"] = company2.iloc[:, [7, 9]].sum(axis = 1)\n",
    "#company2 = company2.drop([\"size_10.0\", \"size_50.0\", \"size_200.0\", \"size_500.0\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 840,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = company2.drop([\"multi_donor\"], axis = 1) \n",
    "y = company2[\"multi_donor\"]\n",
    "#features = pd.get_dummies(features)\n",
    "feature_list = list(features.columns)\n",
    "features = np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 841,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, test_features, train_labels, test_labels = train_test_split(features, y, test_size = 0.25, random_state = 23156)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 842,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators = 1000, random_state = 12356)\n",
    "rf.fit(train_features, train_labels);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 843,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0,\n",
       "       0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1,\n",
       "       1, 1])"
      ]
     },
     "execution_count": 843,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = rf.predict(test_features)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 844,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7083333333333334"
      ]
     },
     "execution_count": 844,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(test_labels == predictions)/len(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 845,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable: last_donation_weeks  Importance: 0.56\n",
      "Variable: size_50.0            Importance: 0.05\n",
      "Variable: state_Underdeveloped Importance: 0.04\n",
      "Variable: comm_edu/health_web  Importance: 0.04\n",
      "Variable: fin_bus              Importance: 0.04\n",
      "Variable: size_10.0            Importance: 0.03\n",
      "Variable: size_1000.0          Importance: 0.03\n",
      "Variable: size_200.0           Importance: 0.03\n",
      "Variable: state_California     Importance: 0.03\n",
      "Variable: state_New York       Importance: 0.03\n",
      "Variable: type_applied         Importance: 0.03\n",
      "Variable: food_other_sale      Importance: 0.03\n",
      "Variable: size_500.0           Importance: 0.02\n",
      "Variable: size_5000.0          Importance: 0.02\n",
      "Variable: size_10000.0         Importance: 0.01\n",
      "Variable: size_10001.0         Importance: 0.01\n",
      "Variable: type_soft            Importance: 0.01\n"
     ]
    }
   ],
   "source": [
    "importances = list(rf.feature_importances_)\n",
    "feature_importances = [(feature, round(importance, 2)) for feature, importance in zip(feature_list, importances)]\n",
    "feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n",
    "[print('Variable: {:20} Importance: {}'.format(*pair)) for pair in feature_importances];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 846,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 50 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   53.6s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done 357 tasks      | elapsed:  5.8min\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:  7.3min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=10, error_score='raise',\n",
       "          estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "          fit_params=None, iid=True, n_iter=50, n_jobs=-1,\n",
       "          param_distributions={'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000], 'max_features': ['auto', 'sqrt'], 'max_depth': [3, 6, 9, 12, 15, 18, 21, 24, 27, 30, 33, 36, 39, 42, 45, 48, 51, 54, 57, 60], 'min_samples_split': [2, 2, 3, 4, 5, 6, 7, 8, 9, 10], 'min_samples_leaf': [1, 2, 3, 4, 5], 'bootstrap': [True, False]},\n",
       "          pre_dispatch='2*n_jobs', random_state=6819, refit=True,\n",
       "          return_train_score='warn', scoring=None, verbose=2)"
      ]
     },
     "execution_count": 846,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid,\n",
    "                              n_iter = 50, cv = 10, verbose = 2, random_state = 6819,\n",
    "                              n_jobs = -1)\n",
    "rf_random.fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 847,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'max_depth': 3,\n",
       " 'max_features': 'sqrt',\n",
       " 'min_samples_leaf': 5,\n",
       " 'min_samples_split': 7,\n",
       " 'n_estimators': 800}"
      ]
     },
     "execution_count": 847,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 858,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6458333333333334"
      ]
     },
     "execution_count": 858,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(bootstrap = True,\n",
    "                            max_depth = 3,\n",
    "                            max_features = \"sqrt\",\n",
    "                            min_samples_leaf = 5,\n",
    "                            min_samples_split = 7,\n",
    "                            n_estimators = 800,\n",
    "                            random_state = 12356)\n",
    "rf.fit(train_features, train_labels);\n",
    "sum(rf.predict(test_features) == test_labels)/len(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 859,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable: last_donation_weeks  Importance: 0.51\n",
      "Variable: size_50.0            Importance: 0.09\n",
      "Variable: state_Underdeveloped Importance: 0.07\n",
      "Variable: size_10.0            Importance: 0.04\n",
      "Variable: size_1000.0          Importance: 0.04\n",
      "Variable: state_New York       Importance: 0.04\n",
      "Variable: size_200.0           Importance: 0.03\n",
      "Variable: state_California     Importance: 0.03\n",
      "Variable: fin_bus              Importance: 0.03\n",
      "Variable: size_500.0           Importance: 0.02\n",
      "Variable: size_5000.0          Importance: 0.02\n",
      "Variable: type_applied         Importance: 0.02\n",
      "Variable: food_other_sale      Importance: 0.02\n",
      "Variable: comm_edu/health_web  Importance: 0.02\n",
      "Variable: type_soft            Importance: 0.01\n",
      "Variable: size_10000.0         Importance: 0.0\n",
      "Variable: size_10001.0         Importance: 0.0\n"
     ]
    }
   ],
   "source": [
    "importances = list(rf.feature_importances_)\n",
    "feature_importances = [(feature, round(importance, 2)) for feature, importance in zip(feature_list, importances)]\n",
    "feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n",
    "[print('Variable: {:20} Importance: {}'.format(*pair)) for pair in feature_importances];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 860,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = rf.predict(test_features)\n",
    "predicted_one_time = [i for i in range(len(preds)) if preds[i] == 1]\n",
    "predicted_multi_time = [i for i in range(len(preds)) if preds[i] == 0]\n",
    "true_one_time = [i for i in range(len(test_labels)) if np.array(test_labels)[i] == 1]\n",
    "true_multi_time = [i for i in range(len(test_labels)) if np.array(test_labels)[i] == 0]\n",
    "true_positives = len(np.intersect1d(predicted_one_time, true_one_time))\n",
    "false_positives = len(np.intersect1d(predicted_one_time, true_multi_time))\n",
    "true_negatives = len(np.intersect1d(predicted_multi_time, true_multi_time))\n",
    "false_negatives = len(np.intersect1d(predicted_multi_time, true_one_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 861,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 861,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "false_negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 862,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9354838709677419"
      ]
     },
     "execution_count": 862,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_positives/(true_positives + false_negatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 863,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 863,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_positives + false_negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 912,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7272727272727273"
      ]
     },
     "execution_count": 912,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_positives/(true_positives + false_positives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
