{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "from pandas.api.types import CategoricalDtype\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.tree import export_graphviz \n",
    "from sklearn.model_selection import KFold\n",
    "from pydot import pydot\n",
    "#cloned into https://github.com/erocarrera/pydot\n",
    "from pydot import dot_parser\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "food = pd.read_csv(\"food_full.csv\")\n",
    "food = food.drop([\"Unnamed: 0\", \"date\"], axis = 1)\n",
    "company = pd.read_csv(\"company_full.csv\")\n",
    "company = company.drop(\"company\", axis = 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking at whether a company would be a one time or multiple time donations before first donation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#features = food.drop([\"Unnamed: 0\", \"Id\", \"date\", \"number\", \"street\", \"city\", \"company\", \"zip\", \"lat\", \"lon\", \"pickup\", \"planned\", \"day\", \"year\"], axis = 1)\n",
    "#features.loc[(features[\"state\"] != \"California\") & (features[\"state\"] != \"New York\"), \"state\"] = \"underdeveloped\"\n",
    "features = company.drop([\"one_donation\"], axis = 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(242, 20)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = company[\"one_donation\"]\n",
    "#features = pd.get_dummies(features)\n",
    "feature_list = list(features.columns)\n",
    "features = np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, test_features, train_labels, test_labels = train_test_split(features, y, test_size = 0.25, random_state = 23156)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators = 1000, random_state = 2756)\n",
    "rf.fit(train_features, train_labels);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
       "       0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = rf.predict(test_features)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7213114754098361"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(test_labels == predictions)/len(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable: size_50.0            Importance: 0.1\n",
      "Variable: size_200.0           Importance: 0.08\n",
      "Variable: size_5000.0          Importance: 0.07\n",
      "Variable: state_California     Importance: 0.06\n",
      "Variable: state_New York       Importance: 0.06\n",
      "Variable: state_underdeveloped Importance: 0.06\n",
      "Variable: type_comm            Importance: 0.06\n",
      "Variable: type_bus             Importance: 0.05\n",
      "Variable: type_food            Importance: 0.05\n",
      "Variable: size_10.0            Importance: 0.05\n",
      "Variable: size_1000.0          Importance: 0.05\n",
      "Variable: type_applied         Importance: 0.04\n",
      "Variable: type_edu-health      Importance: 0.04\n",
      "Variable: type_sale            Importance: 0.04\n",
      "Variable: type_web             Importance: 0.04\n",
      "Variable: type_fin             Importance: 0.03\n",
      "Variable: type_other           Importance: 0.03\n",
      "Variable: type_soft            Importance: 0.03\n",
      "Variable: size_10001.0         Importance: 0.03\n",
      "Variable: size_10000.0         Importance: 0.03\n"
     ]
    }
   ],
   "source": [
    "importances = list(rf.feature_importances_)\n",
    "feature_importances = [(feature, round(importance, 2)) for feature, importance in zip(feature_list, importances)]\n",
    "feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n",
    "[print('Variable: {:20} Importance: {}'.format(*pair)) for pair in feature_importances];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dot_parser' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-158-92df9237c3a3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtree\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mexport_graphviz\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'tree.dot'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeature_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrounded\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprecision\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;33m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpydot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph_from_dot_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'tree.dot'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite_png\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'tree.png'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\replate\\pydot\\pydot.py\u001b[0m in \u001b[0;36mgraph_from_dot_file\u001b[1;34m(path, encoding)\u001b[0m\n\u001b[0;32m    236\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mPY3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m         \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0municode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 238\u001b[1;33m     \u001b[0mgraphs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_from_dot_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    239\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraphs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\replate\\pydot\\pydot.py\u001b[0m in \u001b[0;36mgraph_from_dot_data\u001b[1;34m(s)\u001b[0m\n\u001b[0;32m    219\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mrtype\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mof\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mpydot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m     \"\"\"\n\u001b[1;32m--> 221\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mdot_parser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse_dot_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    222\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dot_parser' is not defined"
     ]
    }
   ],
   "source": [
    "tree = rf.estimators_[5]\n",
    "export_graphviz(tree, out_file = 'tree.dot', feature_names = feature_list, rounded = True, precision = 1)\n",
    "(graph, ) = pydot.graph_from_dot_file('tree.dot')\n",
    "graph.write_png('tree.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "must be str, not ParseException",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mParseException\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\replate\\pydot\\dot_parser.py\u001b[0m in \u001b[0;36mparse_dot_data\u001b[1;34m(s)\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[0mgraphparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparseWithTabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 548\u001b[1;33m         \u001b[0mtokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraphparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparseString\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    549\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jordan fan\\anaconda3\\envs\\toxic\\lib\\site-packages\\pyparsing.py\u001b[0m in \u001b[0;36mparseString\u001b[1;34m(self, instring, parseAll)\u001b[0m\n\u001b[0;32m   1631\u001b[0m                 \u001b[1;31m# catch and re-raise exception from here, clears out pyparsing internal stack trace\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1632\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1633\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jordan fan\\anaconda3\\envs\\toxic\\lib\\site-packages\\pyparsing.py\u001b[0m in \u001b[0;36mparseString\u001b[1;34m(self, instring, parseAll)\u001b[0m\n\u001b[0;32m   1621\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1622\u001b[1;33m             \u001b[0mloc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parse\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0minstring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1623\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mparseAll\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jordan fan\\anaconda3\\envs\\toxic\\lib\\site-packages\\pyparsing.py\u001b[0m in \u001b[0;36m_parseNoCache\u001b[1;34m(self, instring, loc, doActions, callPreParse)\u001b[0m\n\u001b[0;32m   1378\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1379\u001b[1;33m                     \u001b[0mloc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparseImpl\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0minstring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreloc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdoActions\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1380\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jordan fan\\anaconda3\\envs\\toxic\\lib\\site-packages\\pyparsing.py\u001b[0m in \u001b[0;36mparseImpl\u001b[1;34m(self, instring, loc, doActions)\u001b[0m\n\u001b[0;32m   3847\u001b[0m             \u001b[0mtry_not_ender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minstring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3848\u001b[1;33m         \u001b[0mloc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself_expr_parse\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0minstring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdoActions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallPreParse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3849\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jordan fan\\anaconda3\\envs\\toxic\\lib\\site-packages\\pyparsing.py\u001b[0m in \u001b[0;36m_parseNoCache\u001b[1;34m(self, instring, loc, doActions, callPreParse)\u001b[0m\n\u001b[0;32m   1378\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1379\u001b[1;33m                     \u001b[0mloc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparseImpl\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0minstring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreloc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdoActions\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1380\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jordan fan\\anaconda3\\envs\\toxic\\lib\\site-packages\\pyparsing.py\u001b[0m in \u001b[0;36mparseImpl\u001b[1;34m(self, instring, loc, doActions)\u001b[0m\n\u001b[0;32m   3394\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3395\u001b[1;33m                 \u001b[0mloc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexprtokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parse\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0minstring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdoActions\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3396\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mexprtokens\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mexprtokens\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhaskeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jordan fan\\anaconda3\\envs\\toxic\\lib\\site-packages\\pyparsing.py\u001b[0m in \u001b[0;36m_parseNoCache\u001b[1;34m(self, instring, loc, doActions, callPreParse)\u001b[0m\n\u001b[0;32m   1378\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1379\u001b[1;33m                     \u001b[0mloc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparseImpl\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0minstring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreloc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdoActions\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1380\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jordan fan\\anaconda3\\envs\\toxic\\lib\\site-packages\\pyparsing.py\u001b[0m in \u001b[0;36mparseImpl\u001b[1;34m(self, instring, loc, doActions)\u001b[0m\n\u001b[0;32m   3716\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpr\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3717\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parse\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0minstring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdoActions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallPreParse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3718\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jordan fan\\anaconda3\\envs\\toxic\\lib\\site-packages\\pyparsing.py\u001b[0m in \u001b[0;36m_parseNoCache\u001b[1;34m(self, instring, loc, doActions, callPreParse)\u001b[0m\n\u001b[0;32m   1378\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1379\u001b[1;33m                     \u001b[0mloc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparseImpl\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0minstring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreloc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdoActions\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1380\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jordan fan\\anaconda3\\envs\\toxic\\lib\\site-packages\\pyparsing.py\u001b[0m in \u001b[0;36mparseImpl\u001b[1;34m(self, instring, loc, doActions)\u001b[0m\n\u001b[0;32m   3544\u001b[0m                 \u001b[0mmaxException\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmsg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrmsg\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3545\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mmaxException\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3546\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jordan fan\\anaconda3\\envs\\toxic\\lib\\site-packages\\pyparsing.py\u001b[0m in \u001b[0;36mparseImpl\u001b[1;34m(self, instring, loc, doActions)\u001b[0m\n\u001b[0;32m   3529\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3530\u001b[1;33m                 \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parse\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0minstring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdoActions\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3531\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jordan fan\\anaconda3\\envs\\toxic\\lib\\site-packages\\pyparsing.py\u001b[0m in \u001b[0;36m_parseNoCache\u001b[1;34m(self, instring, loc, doActions, callPreParse)\u001b[0m\n\u001b[0;32m   1382\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1383\u001b[1;33m                 \u001b[0mloc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparseImpl\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0minstring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreloc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdoActions\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1384\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jordan fan\\anaconda3\\envs\\toxic\\lib\\site-packages\\pyparsing.py\u001b[0m in \u001b[0;36mparseImpl\u001b[1;34m(self, instring, loc, doActions)\u001b[0m\n\u001b[0;32m   2502\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mloc\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatchLen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreturnString\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2503\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mParseException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minstring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2504\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mParseException\u001b[0m: Expected {'graph' | 'digraph'} (at char 0), (line:1, col:1)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-159-27247b356934>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdot_parser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse_dot_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"tree.dot\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\replate\\pydot\\dot_parser.py\u001b[0m in \u001b[0;36mparse_dot_data\u001b[1;34m(s)\u001b[0m\n\u001b[0;32m    552\u001b[0m             \u001b[0merr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mline\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    553\u001b[0m             \u001b[1;34m\" \"\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"^\"\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 554\u001b[1;33m             err)\n\u001b[0m\u001b[0;32m    555\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: must be str, not ParseException"
     ]
    }
   ],
   "source": [
    "dot_parser.parse_dot_data(\"tree.dot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "max_features = [\"auto\", \"sqrt\"]\n",
    "max_depth = [int(x) for x in np.linspace(start = 3, stop = 60, num = 20)] \n",
    "#max_depth.append(None)\n",
    "min_samples_split = [int(x) for x in np.linspace(start = 2, stop = 10, num = 10)]\n",
    "min_samples_leaf = [int(x) for x in np.linspace(start = 1, stop = 5, num = 5)]\n",
    "bootstrap = [True, False] \n",
    "\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'random_grid' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-f9f12e0bc15c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mrf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid,\n\u001b[0m\u001b[0;32m      3\u001b[0m                               \u001b[0mn_iter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m6819\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                               n_jobs = -1)\n\u001b[0;32m      5\u001b[0m \u001b[0mrf_random\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'random_grid' is not defined"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid,\n",
    "                              n_iter = 100, cv = 10, verbose = 2, random_state = 6819,\n",
    "                              n_jobs = -1)\n",
    "rf_random.fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'max_depth': 3,\n",
       " 'max_features': 'auto',\n",
       " 'min_samples_leaf': 3,\n",
       " 'min_samples_split': 5,\n",
       " 'n_estimators': 1800}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'max_depth': 3,\n",
       " 'max_features': 'sqrt',\n",
       " 'min_samples_leaf': 5,\n",
       " 'min_samples_split': 7,\n",
       " 'n_estimators': 800}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators = 800, \n",
    "                            bootstrap = True,\n",
    "                            max_depth = 3,\n",
    "                            max_features = \"sqrt\",\n",
    "                            min_samples_leaf = 5,\n",
    "                            min_samples_split = 7,\n",
    "                            random_state = 2332)\n",
    "rf.fit(train_features, train_labels);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable: state_underdeveloped Importance: 0.19\n",
      "Variable: size_1000.0          Importance: 0.16\n",
      "Variable: size_50.0            Importance: 0.07\n",
      "Variable: state_California     Importance: 0.06\n",
      "Variable: state_New York       Importance: 0.06\n",
      "Variable: type_applied         Importance: 0.06\n",
      "Variable: type_comm            Importance: 0.06\n",
      "Variable: type_edu-health      Importance: 0.05\n",
      "Variable: type_bus             Importance: 0.04\n",
      "Variable: type_sale            Importance: 0.04\n",
      "Variable: type_fin             Importance: 0.03\n",
      "Variable: type_food            Importance: 0.03\n",
      "Variable: size_5000.0          Importance: 0.03\n",
      "Variable: size_200.0           Importance: 0.03\n",
      "Variable: type_other           Importance: 0.02\n",
      "Variable: type_soft            Importance: 0.02\n",
      "Variable: type_web             Importance: 0.02\n",
      "Variable: size_10.0            Importance: 0.02\n",
      "Variable: size_10001.0         Importance: 0.02\n",
      "Variable: size_10000.0         Importance: 0.0\n"
     ]
    }
   ],
   "source": [
    "importances = list(rf.feature_importances_)\n",
    "feature_importances = [(feature, round(importance, 2)) for feature, importance in zip(feature_list, importances)]\n",
    "feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n",
    "[print('Variable: {:20} Importance: {}'.format(*pair)) for pair in feature_importances];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7213114754098361"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(rf.predict(test_features) == test_labels)/len(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision Score: 0.67\n",
      "Recall Score: 0.21\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "precision_accuracy = precision_score(test_labels, rf.predict(test_features))\n",
    "recall_accuracy = recall_score(test_labels, rf.predict(test_features))\n",
    "\n",
    "print('Precision Score: {0:0.2f}'.format(\n",
    "      precision_accuracy))\n",
    "print('Recall Score: {0:0.2f}'.format(\n",
    "      recall_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = rf.predict(test_features)\n",
    "predicted_one_time = [i for i in range(len(preds)) if preds[i] == 1]\n",
    "predicted_multi_time = [i for i in range(len(preds)) if preds[i] == 0]\n",
    "true_one_time = [i for i in range(len(test_labels)) if np.array(test_labels)[i] == 1]\n",
    "true_multi_time = [i for i in range(len(test_labels)) if np.array(test_labels)[i] == 0]\n",
    "true_positives = len(np.intersect1d(predicted_one_time, true_one_time))\n",
    "false_positives = len(np.intersect1d(predicted_one_time, true_multi_time))\n",
    "true_negatives = len(np.intersect1d(predicted_multi_time, true_multi_time))\n",
    "false_negatives = len(np.intersect1d(predicted_multi_time, true_one_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = true_positives/(true_positives + false_positives)\n",
    "recall = true_positives/(true_positives + false_negatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666666 0.21052631578947367\n"
     ]
    }
   ],
   "source": [
    "print(precision, recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "false_negatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A lot of false negatives: assume more companies are multi-time donors when they are in fact one time donors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6885245901639344"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(test_labels == 0)/len(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing which company types can be combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['food', 'other', 'comm', 'fin', 'soft', 'bus', 'edu-health',\n",
       "       'applied', 'web', 'sale'], dtype=object)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "food[\"type\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_food = company[company[\"type_food\"] == 1][\"one_donation\"]\n",
    "company_other = company[company[\"type_other\"] == 1][\"one_donation\"]\n",
    "company_comm = company[company[\"type_comm\"] == 1][\"one_donation\"]\n",
    "company_fin = company[company[\"type_fin\"] == 1][\"one_donation\"]\n",
    "company_soft = company[company[\"type_soft\"] == 1][\"one_donation\"]\n",
    "company_bus = company[company[\"type_bus\"] == 1][\"one_donation\"]\n",
    "company_eh = company[company[\"type_edu-health\"] == 1][\"one_donation\"]\n",
    "company_applied = company[company[\"type_applied\"] == 1][\"one_donation\"]\n",
    "company_web = company[company[\"type_web\"] == 1][\"one_donation\"]\n",
    "company_sale = company[company[\"type_sale\"] == 1][\"one_donation\"]\n",
    "dists_name = [\"Food\", \"Other\", \"Communication\", \"Finance\", \"Software\", \n",
    "             \"Business\", \"Education-Health\", \"Applied\", \"Web\", \"Sale\"]\n",
    "dists = [company_food, company_other, company_comm, company_fin, company_soft,\n",
    "        company_bus, company_eh, company_applied, company_web, company_sale]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "props = []\n",
    "for i in range(len(dists)):\n",
    "    props.append(sum(dists[i] == 1)/len(dists[i]))\n",
    "props = np.array(props)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "food 0.371428571429\n",
      "other 0.352941176471\n",
      "comm 0.423076923077\n",
      "fin 0.296296296296\n",
      "soft 0.1875\n",
      "bus 0.290322580645\n",
      "edu-health 0.428571428571\n",
      "applied 0.454545454545\n",
      "web 0.421052631579\n",
      "sale 0.352941176471\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(props)):\n",
    "    print(food[\"type\"].unique()[i], props[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Food and Other: 0.45\n",
      "Food and Communication: 0.34\n",
      "Food and Finance: 0.27\n",
      "Food and Software: 0.09\n",
      "Food and Business: 0.24\n",
      "Food and Education-Health: 0.34\n",
      "Food and Applied: 0.24\n",
      "Food and Web: 0.36\n",
      "Food and Sale: 0.45\n"
     ]
    }
   ],
   "source": [
    "print()\n",
    "for i in range(1, len(dists)): \n",
    "    n1 = len(dists[0])\n",
    "    n2 = len(dists[i])\n",
    "    p1 = props[0]\n",
    "    p2 = props[i]\n",
    "    p = (n1 * p1 + n2 * p2)/(n1 + n2)\n",
    "    z = (p1 - p2)/(p * (1 - p) * (1/n1 + 1/n2))**0.5\n",
    "    print(\"Food and \" + dists_name[i] + ': {0:0.2f}'.format(\n",
    "     1 - norm.cdf(abs(z))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Other and Communication: 0.32\n",
      "Other and Finance: 0.35\n",
      "Other and Software: 0.14\n",
      "Other and Business: 0.33\n",
      "Other and Education-Health: 0.32\n",
      "Other and Applied: 0.25\n",
      "Other and Web: 0.34\n",
      "Other and Sale: 0.50\n"
     ]
    }
   ],
   "source": [
    "for i in range(2, len(dists)): \n",
    "    n1 = len(dists[1])\n",
    "    n2 = len(dists[i])\n",
    "    p1 = props[1]\n",
    "    p2 = props[i]\n",
    "    p = (n1 * p1 + n2 * p2)/(n1 + n2)\n",
    "    z = (p1 - p2)/(p * (1 - p) * (1/n1 + 1/n2))**0.5\n",
    "    print(\"Other and \" + dists_name[i] + ': {0:0.2f}'.format(\n",
    "     1 - norm.cdf(abs(z))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Communication and Finance: 0.17\n",
      "Communication and Software: 0.06\n",
      "Communication and Business: 0.15\n",
      "Communication and Education-Health: 0.48\n",
      "Communication and Applied: 0.40\n",
      "Communication and Web: 0.49\n",
      "Communication and Sale: 0.32\n"
     ]
    }
   ],
   "source": [
    "for i in range(3, len(dists)): \n",
    "    n1 = len(dists[2])\n",
    "    n2 = len(dists[i])\n",
    "    p1 = props[2]\n",
    "    p2 = props[i]\n",
    "    p = (n1 * p1 + n2 * p2)/(n1 + n2)\n",
    "    z = (p1 - p2)/(p * (1 - p) * (1/n1 + 1/n2))**0.5\n",
    "    print(\"Communication and \" + dists_name[i] + ': {0:0.2f}'.format(\n",
    "      1 - norm.cdf(abs(z))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finance and Software: 0.21\n",
      "Finance and Business: 0.48\n",
      "Finance and Education-Health: 0.17\n",
      "Finance and Applied: 0.10\n",
      "Finance and Web: 0.19\n",
      "Finance and Sale: 0.35\n"
     ]
    }
   ],
   "source": [
    "for i in range(4, len(dists)): \n",
    "    n1 = len(dists[3])\n",
    "    n2 = len(dists[i])\n",
    "    p1 = props[3]\n",
    "    p2 = props[i]\n",
    "    p = (n1 * p1 + n2 * p2)/(n1 + n2)\n",
    "    z = (p1 - p2)/(p * (1 - p) * (1/n1 + 1/n2))**0.5\n",
    "    print(\"Finance and \" + dists_name[i] + ': {0:0.2f}'.format(\n",
    "      1 - norm.cdf(abs(z))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Software and Business: 0.22\n",
      "Software and Education-Health: 0.06\n",
      "Software and Applied: 0.03\n",
      "Software and Web: 0.07\n",
      "Software and Sale: 0.14\n"
     ]
    }
   ],
   "source": [
    "for i in range(5, len(dists)): \n",
    "    n1 = len(dists[4])\n",
    "    n2 = len(dists[i])\n",
    "    p1 = props[4]\n",
    "    p2 = props[i]\n",
    "    p = (n1 * p1 + n2 * p2)/(n1 + n2)\n",
    "    z = (p1 - p2)/(p * (1 - p) * (1/n1 + 1/n2))**0.5\n",
    "    print(\"Software and \" + dists_name[i] + ': {0:0.2f}'.format(\n",
    "      1 - norm.cdf(abs(z))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Business and Education-Health: 0.15\n",
      "Business and Applied: 0.09\n",
      "Business and Web: 0.17\n",
      "Business and Sale: 0.33\n"
     ]
    }
   ],
   "source": [
    "for i in range(6, len(dists)): \n",
    "    n1 = len(dists[5])\n",
    "    n2 = len(dists[i])\n",
    "    p1 = props[5]\n",
    "    p2 = props[i]\n",
    "    p = (n1 * p1 + n2 * p2)/(n1 + n2)\n",
    "    z = (p1 - p2)/(p * (1 - p) * (1/n1 + 1/n2))**0.5\n",
    "    print(\"Business and \" + dists_name[i] + ': {0:0.2f}'.format(\n",
    "      1 - norm.cdf(abs(z))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Education-Health and Applied: 0.43\n",
      "Education-Health and Web: 0.48\n",
      "Education-Health and Sale: 0.32\n"
     ]
    }
   ],
   "source": [
    "for i in range(7, len(dists)): \n",
    "    n1 = len(dists[6])\n",
    "    n2 = len(dists[i])\n",
    "    p1 = props[6]\n",
    "    p2 = props[i]\n",
    "    p = (n1 * p1 + n2 * p2)/(n1 + n2)\n",
    "    z = (p1 - p2)/(p * (1 - p) * (1/n1 + 1/n2))**0.5\n",
    "    print(\"Education-Health and \" + dists_name[i] + ': {0:0.2f}'.format(\n",
    "      1 - norm.cdf(abs(z))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied and Web: 0.41\n",
      "Applied and Sale: 0.25\n"
     ]
    }
   ],
   "source": [
    "for i in range(8, len(dists)): \n",
    "    n1 = len(dists[7])\n",
    "    n2 = len(dists[i])\n",
    "    p1 = props[7]\n",
    "    p2 = props[i]\n",
    "    p = (n1 * p1 + n2 * p2)/(n1 + n2)\n",
    "    z = (p1 - p2)/(p * (1 - p) * (1/n1 + 1/n2))**0.5\n",
    "    print(\"Applied and \" + dists_name[i] + ': {0:0.2f}'.format(\n",
    "      1 - norm.cdf(abs(z))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Web and Sale: 0.34\n"
     ]
    }
   ],
   "source": [
    "for i in range(9, len(dists)): \n",
    "    n1 = len(dists[8])\n",
    "    n2 = len(dists[i])\n",
    "    p1 = props[8]\n",
    "    p2 = props[i]\n",
    "    p = (n1 * p1 + n2 * p2)/(n1 + n2)\n",
    "    z = (p1 - p2)/(p * (1 - p) * (1/n1 + 1/n2))**0.5\n",
    "    print(\"Web and \" + dists_name[i] + ': {0:0.2f}'.format(\n",
    "      1 - norm.cdf(abs(z))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
