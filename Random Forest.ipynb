{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jordan Fan\\replate\\pydot\\pydot.py:17: UserWarning: Couldn't import dot_parser, loading of dot files will not be possible.\n",
      "  \"Couldn't import dot_parser, \"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "from pandas.api.types import CategoricalDtype\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.tree import export_graphviz \n",
    "from sklearn.model_selection import KFold\n",
    "from pydot import pydot\n",
    "#cloned into https://github.com/erocarrera/pydot\n",
    "from pydot import dot_parser\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "food = pd.read_csv(\"food_full.csv\")\n",
    "food = food.drop([\"Unnamed: 0\", \"date\"], axis = 1)\n",
    "company = pd.read_csv(\"company_full.csv\")\n",
    "company = company.drop(\"company\", axis = 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking at whether a company would be a one time or multiple time donations before first donation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "#features = food.drop([\"Unnamed: 0\", \"Id\", \"date\", \"number\", \"street\", \"city\", \"company\", \"zip\", \"lat\", \"lon\", \"pickup\", \"planned\", \"day\", \"year\"], axis = 1)\n",
    "#features.loc[(features[\"state\"] != \"California\") & (features[\"state\"] != \"New York\"), \"state\"] = \"underdeveloped\"\n",
    "features = company.drop([\"one_donation\"], axis = 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(242, 16)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = company[\"one_donation\"]\n",
    "#features = pd.get_dummies(features)\n",
    "feature_list = list(features.columns)\n",
    "features = np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, test_features, train_labels, test_labels = train_test_split(features, y, test_size = 0.25, random_state = 23156)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators = 1000, random_state = 2756)\n",
    "rf.fit(train_features, train_labels);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
       "       1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = rf.predict(test_features)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7213114754098361"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(test_labels == predictions)/len(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable: state_underdeveloped Importance: 0.09\n",
      "Variable: size_50.0            Importance: 0.08\n",
      "Variable: size_500.0           Importance: 0.08\n",
      "Variable: state_New York       Importance: 0.08\n",
      "Variable: size_200.0           Importance: 0.07\n",
      "Variable: state_California     Importance: 0.07\n",
      "Variable: fos                  Importance: 0.07\n",
      "Variable: cew                  Importance: 0.07\n",
      "Variable: size_1000.0          Importance: 0.06\n",
      "Variable: size_5000.0          Importance: 0.06\n",
      "Variable: type_applied         Importance: 0.06\n",
      "Variable: fb                   Importance: 0.06\n",
      "Variable: size_10.0            Importance: 0.04\n",
      "Variable: size_10001.0         Importance: 0.04\n",
      "Variable: type_soft            Importance: 0.04\n",
      "Variable: size_10000.0         Importance: 0.03\n"
     ]
    }
   ],
   "source": [
    "importances = list(rf.feature_importances_)\n",
    "feature_importances = [(feature, round(importance, 2)) for feature, importance in zip(feature_list, importances)]\n",
    "feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n",
    "[print('Variable: {:20} Importance: {}'.format(*pair)) for pair in feature_importances];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dot_parser' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-92df9237c3a3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtree\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mexport_graphviz\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'tree.dot'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeature_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrounded\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprecision\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;33m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpydot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph_from_dot_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'tree.dot'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite_png\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'tree.png'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\replate\\pydot\\pydot.py\u001b[0m in \u001b[0;36mgraph_from_dot_file\u001b[1;34m(path, encoding)\u001b[0m\n\u001b[0;32m    236\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mPY3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m         \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0municode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 238\u001b[1;33m     \u001b[0mgraphs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_from_dot_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    239\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraphs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\replate\\pydot\\pydot.py\u001b[0m in \u001b[0;36mgraph_from_dot_data\u001b[1;34m(s)\u001b[0m\n\u001b[0;32m    219\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mrtype\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mof\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mpydot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m     \"\"\"\n\u001b[1;32m--> 221\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mdot_parser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse_dot_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    222\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dot_parser' is not defined"
     ]
    }
   ],
   "source": [
    "tree = rf.estimators_[5]\n",
    "export_graphviz(tree, out_file = 'tree.dot', feature_names = feature_list, rounded = True, precision = 1)\n",
    "(graph, ) = pydot.graph_from_dot_file('tree.dot')\n",
    "graph.write_png('tree.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "must be str, not ParseException",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mParseException\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\replate\\pydot\\dot_parser.py\u001b[0m in \u001b[0;36mparse_dot_data\u001b[1;34m(s)\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[0mgraphparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparseWithTabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 548\u001b[1;33m         \u001b[0mtokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraphparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparseString\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    549\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jordan fan\\anaconda3\\envs\\toxic\\lib\\site-packages\\pyparsing.py\u001b[0m in \u001b[0;36mparseString\u001b[1;34m(self, instring, parseAll)\u001b[0m\n\u001b[0;32m   1631\u001b[0m                 \u001b[1;31m# catch and re-raise exception from here, clears out pyparsing internal stack trace\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1632\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1633\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jordan fan\\anaconda3\\envs\\toxic\\lib\\site-packages\\pyparsing.py\u001b[0m in \u001b[0;36mparseString\u001b[1;34m(self, instring, parseAll)\u001b[0m\n\u001b[0;32m   1621\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1622\u001b[1;33m             \u001b[0mloc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parse\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0minstring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1623\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mparseAll\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jordan fan\\anaconda3\\envs\\toxic\\lib\\site-packages\\pyparsing.py\u001b[0m in \u001b[0;36m_parseNoCache\u001b[1;34m(self, instring, loc, doActions, callPreParse)\u001b[0m\n\u001b[0;32m   1378\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1379\u001b[1;33m                     \u001b[0mloc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparseImpl\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0minstring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreloc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdoActions\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1380\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jordan fan\\anaconda3\\envs\\toxic\\lib\\site-packages\\pyparsing.py\u001b[0m in \u001b[0;36mparseImpl\u001b[1;34m(self, instring, loc, doActions)\u001b[0m\n\u001b[0;32m   3847\u001b[0m             \u001b[0mtry_not_ender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minstring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3848\u001b[1;33m         \u001b[0mloc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself_expr_parse\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0minstring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdoActions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallPreParse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3849\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jordan fan\\anaconda3\\envs\\toxic\\lib\\site-packages\\pyparsing.py\u001b[0m in \u001b[0;36m_parseNoCache\u001b[1;34m(self, instring, loc, doActions, callPreParse)\u001b[0m\n\u001b[0;32m   1378\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1379\u001b[1;33m                     \u001b[0mloc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparseImpl\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0minstring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreloc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdoActions\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1380\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jordan fan\\anaconda3\\envs\\toxic\\lib\\site-packages\\pyparsing.py\u001b[0m in \u001b[0;36mparseImpl\u001b[1;34m(self, instring, loc, doActions)\u001b[0m\n\u001b[0;32m   3394\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3395\u001b[1;33m                 \u001b[0mloc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexprtokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parse\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0minstring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdoActions\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3396\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mexprtokens\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mexprtokens\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhaskeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jordan fan\\anaconda3\\envs\\toxic\\lib\\site-packages\\pyparsing.py\u001b[0m in \u001b[0;36m_parseNoCache\u001b[1;34m(self, instring, loc, doActions, callPreParse)\u001b[0m\n\u001b[0;32m   1378\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1379\u001b[1;33m                     \u001b[0mloc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparseImpl\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0minstring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreloc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdoActions\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1380\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jordan fan\\anaconda3\\envs\\toxic\\lib\\site-packages\\pyparsing.py\u001b[0m in \u001b[0;36mparseImpl\u001b[1;34m(self, instring, loc, doActions)\u001b[0m\n\u001b[0;32m   3716\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpr\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3717\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parse\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0minstring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdoActions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallPreParse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3718\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jordan fan\\anaconda3\\envs\\toxic\\lib\\site-packages\\pyparsing.py\u001b[0m in \u001b[0;36m_parseNoCache\u001b[1;34m(self, instring, loc, doActions, callPreParse)\u001b[0m\n\u001b[0;32m   1378\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1379\u001b[1;33m                     \u001b[0mloc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparseImpl\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0minstring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreloc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdoActions\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1380\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jordan fan\\anaconda3\\envs\\toxic\\lib\\site-packages\\pyparsing.py\u001b[0m in \u001b[0;36mparseImpl\u001b[1;34m(self, instring, loc, doActions)\u001b[0m\n\u001b[0;32m   3544\u001b[0m                 \u001b[0mmaxException\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmsg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrmsg\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3545\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mmaxException\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3546\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jordan fan\\anaconda3\\envs\\toxic\\lib\\site-packages\\pyparsing.py\u001b[0m in \u001b[0;36mparseImpl\u001b[1;34m(self, instring, loc, doActions)\u001b[0m\n\u001b[0;32m   3529\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3530\u001b[1;33m                 \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parse\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0minstring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdoActions\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3531\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jordan fan\\anaconda3\\envs\\toxic\\lib\\site-packages\\pyparsing.py\u001b[0m in \u001b[0;36m_parseNoCache\u001b[1;34m(self, instring, loc, doActions, callPreParse)\u001b[0m\n\u001b[0;32m   1382\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1383\u001b[1;33m                 \u001b[0mloc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparseImpl\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0minstring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreloc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdoActions\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1384\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jordan fan\\anaconda3\\envs\\toxic\\lib\\site-packages\\pyparsing.py\u001b[0m in \u001b[0;36mparseImpl\u001b[1;34m(self, instring, loc, doActions)\u001b[0m\n\u001b[0;32m   2502\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mloc\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatchLen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreturnString\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2503\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mParseException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minstring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2504\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mParseException\u001b[0m: Expected {'graph' | 'digraph'} (at char 0), (line:1, col:1)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-159-27247b356934>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdot_parser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse_dot_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"tree.dot\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\replate\\pydot\\dot_parser.py\u001b[0m in \u001b[0;36mparse_dot_data\u001b[1;34m(s)\u001b[0m\n\u001b[0;32m    552\u001b[0m             \u001b[0merr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mline\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    553\u001b[0m             \u001b[1;34m\" \"\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"^\"\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 554\u001b[1;33m             err)\n\u001b[0m\u001b[0;32m    555\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: must be str, not ParseException"
     ]
    }
   ],
   "source": [
    "dot_parser.parse_dot_data(\"tree.dot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "max_features = [\"auto\", \"sqrt\"]\n",
    "max_depth = [int(x) for x in np.linspace(start = 3, stop = 60, num = 20)] \n",
    "#max_depth.append(None)\n",
    "min_samples_split = [int(x) for x in np.linspace(start = 2, stop = 10, num = 10)]\n",
    "min_samples_leaf = [int(x) for x in np.linspace(start = 1, stop = 5, num = 5)]\n",
    "bootstrap = [True, False] \n",
    "\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 50 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   29.6s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 357 tasks      | elapsed:  6.6min\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:  7.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=10, error_score='raise',\n",
       "          estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "          fit_params=None, iid=True, n_iter=50, n_jobs=-1,\n",
       "          param_distributions={'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000], 'max_features': ['auto', 'sqrt'], 'max_depth': [3, 6, 9, 12, 15, 18, 21, 24, 27, 30, 33, 36, 39, 42, 45, 48, 51, 54, 57, 60], 'min_samples_split': [2, 2, 3, 4, 5, 6, 7, 8, 9, 10], 'min_samples_leaf': [1, 2, 3, 4, 5], 'bootstrap': [True, False]},\n",
       "          pre_dispatch='2*n_jobs', random_state=6819, refit=True,\n",
       "          return_train_score='warn', scoring=None, verbose=2)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid,\n",
    "                              n_iter = 50, cv = 10, verbose = 2, random_state = 6819,\n",
    "                              n_jobs = -1)\n",
    "rf_random.fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'max_depth': 3,\n",
       " 'max_features': 'sqrt',\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 8,\n",
       " 'n_estimators': 1000}"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators = 1000, \n",
    "                            bootstrap = True,\n",
    "                            max_depth = 3,\n",
    "                            max_features = \"sqrt\",\n",
    "                            min_samples_leaf = 1,\n",
    "                            min_samples_split = 8,\n",
    "                            random_state = 5123)\n",
    "rf.fit(train_features, train_labels);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable: state_underdeveloped Importance: 0.22\n",
      "Variable: size_1000.0          Importance: 0.14\n",
      "Variable: size_50.0            Importance: 0.06\n",
      "Variable: state_California     Importance: 0.06\n",
      "Variable: cew                  Importance: 0.06\n",
      "Variable: fb                   Importance: 0.06\n",
      "Variable: size_500.0           Importance: 0.05\n",
      "Variable: state_New York       Importance: 0.05\n",
      "Variable: type_applied         Importance: 0.05\n",
      "Variable: size_10001.0         Importance: 0.04\n",
      "Variable: size_200.0           Importance: 0.04\n",
      "Variable: type_soft            Importance: 0.04\n",
      "Variable: fos                  Importance: 0.04\n",
      "Variable: size_10.0            Importance: 0.03\n",
      "Variable: size_10000.0         Importance: 0.03\n",
      "Variable: size_5000.0          Importance: 0.03\n"
     ]
    }
   ],
   "source": [
    "importances = list(rf.feature_importances_)\n",
    "feature_importances = [(feature, round(importance, 2)) for feature, importance in zip(feature_list, importances)]\n",
    "feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n",
    "[print('Variable: {:20} Importance: {}'.format(*pair)) for pair in feature_importances];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7213114754098361"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(rf.predict(test_features) == test_labels)/len(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision Score: 0.67\n",
      "Recall Score: 0.21\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "precision_accuracy = precision_score(test_labels, rf.predict(test_features))\n",
    "recall_accuracy = recall_score(test_labels, rf.predict(test_features))\n",
    "\n",
    "print('Precision Score: {0:0.2f}'.format(\n",
    "      precision_accuracy))\n",
    "print('Recall Score: {0:0.2f}'.format(\n",
    "      recall_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = rf.predict(test_features)\n",
    "predicted_one_time = [i for i in range(len(preds)) if preds[i] == 1]\n",
    "predicted_multi_time = [i for i in range(len(preds)) if preds[i] == 0]\n",
    "true_one_time = [i for i in range(len(test_labels)) if np.array(test_labels)[i] == 1]\n",
    "true_multi_time = [i for i in range(len(test_labels)) if np.array(test_labels)[i] == 0]\n",
    "true_positives = len(np.intersect1d(predicted_one_time, true_one_time))\n",
    "false_positives = len(np.intersect1d(predicted_one_time, true_multi_time))\n",
    "true_negatives = len(np.intersect1d(predicted_multi_time, true_multi_time))\n",
    "false_negatives = len(np.intersect1d(predicted_multi_time, true_one_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = true_positives/(true_positives + false_positives)\n",
    "recall = true_positives/(true_positives + false_negatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666666 0.21052631578947367\n"
     ]
    }
   ],
   "source": [
    "print(precision, recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "false_negatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A lot of false negatives: assume more companies are multi-time donors when they are in fact one time donors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6885245901639344"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(test_labels == 0)/len(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing which company types can be combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['food', 'other', 'comm', 'fin', 'soft', 'bus', 'edu-health',\n",
       "       'applied', 'web', 'sale'], dtype=object)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "food[\"type\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_food = company[company[\"type_food\"] == 1][\"one_donation\"]\n",
    "company_other = company[company[\"type_other\"] == 1][\"one_donation\"]\n",
    "company_comm = company[company[\"type_comm\"] == 1][\"one_donation\"]\n",
    "company_fin = company[company[\"type_fin\"] == 1][\"one_donation\"]\n",
    "company_soft = company[company[\"type_soft\"] == 1][\"one_donation\"]\n",
    "company_bus = company[company[\"type_bus\"] == 1][\"one_donation\"]\n",
    "company_eh = company[company[\"type_edu-health\"] == 1][\"one_donation\"]\n",
    "company_applied = company[company[\"type_applied\"] == 1][\"one_donation\"]\n",
    "company_web = company[company[\"type_web\"] == 1][\"one_donation\"]\n",
    "company_sale = company[company[\"type_sale\"] == 1][\"one_donation\"]\n",
    "dists_name = [\"Food\", \"Other\", \"Communication\", \"Finance\", \"Software\", \n",
    "             \"Business\", \"Education-Health\", \"Applied\", \"Web\", \"Sale\"]\n",
    "dists = [company_food, company_other, company_comm, company_fin, company_soft,\n",
    "        company_bus, company_eh, company_applied, company_web, company_sale]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "props = []\n",
    "for i in range(len(dists)):\n",
    "    dist = np.random.choice(dists[i], size = 1000)\n",
    "    props.append(sum(dist == 1)/1000)\n",
    "props = np.array(props)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company Type and Proportions:\n",
      "food 0.354\n",
      "other 0.353\n",
      "comm 0.444\n",
      "fin 0.296\n",
      "soft 0.186\n",
      "bus 0.306\n",
      "edu-health 0.418\n",
      "applied 0.471\n",
      "web 0.413\n",
      "sale 0.35\n"
     ]
    }
   ],
   "source": [
    "print(\"Company Type and Proportions:\")\n",
    "for i in range(len(props)):\n",
    "    print(food[\"type\"].unique()[i], props[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Food and Other: 0.48\n",
      "Food and Communication: 0.00\n",
      "Food and Finance: 0.00\n",
      "Food and Software: 0.00\n",
      "Food and Business: 0.01\n",
      "Food and Education-Health: 0.00\n",
      "Food and Applied: 0.00\n",
      "Food and Web: 0.00\n",
      "Food and Sale: 0.43\n"
     ]
    }
   ],
   "source": [
    "print()\n",
    "for i in range(1, len(dists)): \n",
    "    n1 = 1000\n",
    "    n2 = 1000\n",
    "    p1 = props[0]\n",
    "    p2 = props[i]\n",
    "    p = (n1 * p1 + n2 * p2)/(n1 + n2)\n",
    "    z = (p1 - p2)/(p * (1 - p) * (1/n1 + 1/n2))**0.5\n",
    "    print(\"Food and \" + dists_name[i] + ': {0:0.2f}'.format(\n",
    "     1 - norm.cdf(abs(z))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Other and Communication: 0.00\n",
      "Other and Finance: 0.00\n",
      "Other and Software: 0.00\n",
      "Other and Business: 0.01\n",
      "Other and Education-Health: 0.00\n",
      "Other and Applied: 0.00\n",
      "Other and Web: 0.00\n",
      "Other and Sale: 0.44\n"
     ]
    }
   ],
   "source": [
    "for i in range(2, len(dists)): \n",
    "    n1 = 1000\n",
    "    n2 = 1000\n",
    "    p1 = props[1]\n",
    "    p2 = props[i]\n",
    "    p = (n1 * p1 + n2 * p2)/(n1 + n2)\n",
    "    z = (p1 - p2)/(p * (1 - p) * (1/n1 + 1/n2))**0.5\n",
    "    print(\"Other and \" + dists_name[i] + ': {0:0.2f}'.format(\n",
    "     1 - norm.cdf(abs(z))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Communication and Finance: 0.00\n",
      "Communication and Software: 0.00\n",
      "Communication and Business: 0.00\n",
      "Communication and Education-Health: 0.12\n",
      "Communication and Applied: 0.11\n",
      "Communication and Web: 0.08\n",
      "Communication and Sale: 0.00\n"
     ]
    }
   ],
   "source": [
    "for i in range(3, len(dists)): \n",
    "    n1 = 1000\n",
    "    n2 = 1000\n",
    "    p1 = props[2]\n",
    "    p2 = props[i]\n",
    "    p = (n1 * p1 + n2 * p2)/(n1 + n2)\n",
    "    z = (p1 - p2)/(p * (1 - p) * (1/n1 + 1/n2))**0.5\n",
    "    print(\"Communication and \" + dists_name[i] + ': {0:0.2f}'.format(\n",
    "      1 - norm.cdf(abs(z))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finance and Software: 0.00\n",
      "Finance and Business: 0.31\n",
      "Finance and Education-Health: 0.00\n",
      "Finance and Applied: 0.00\n",
      "Finance and Web: 0.00\n",
      "Finance and Sale: 0.00\n"
     ]
    }
   ],
   "source": [
    "for i in range(4, len(dists)): \n",
    "    n1 = 1000\n",
    "    n2 = 1000\n",
    "    p1 = props[3]\n",
    "    p2 = props[i]\n",
    "    p = (n1 * p1 + n2 * p2)/(n1 + n2)\n",
    "    z = (p1 - p2)/(p * (1 - p) * (1/n1 + 1/n2))**0.5\n",
    "    print(\"Finance and \" + dists_name[i] + ': {0:0.2f}'.format(\n",
    "      1 - norm.cdf(abs(z))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Software and Business: 0.00\n",
      "Software and Education-Health: 0.00\n",
      "Software and Applied: 0.00\n",
      "Software and Web: 0.00\n",
      "Software and Sale: 0.00\n"
     ]
    }
   ],
   "source": [
    "for i in range(5, len(dists)): \n",
    "    n1 = 1000\n",
    "    n2 = 1000\n",
    "    p1 = props[4]\n",
    "    p2 = props[i]\n",
    "    p = (n1 * p1 + n2 * p2)/(n1 + n2)\n",
    "    z = (p1 - p2)/(p * (1 - p) * (1/n1 + 1/n2))**0.5\n",
    "    print(\"Software and \" + dists_name[i] + ': {0:0.2f}'.format(\n",
    "      1 - norm.cdf(abs(z))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Business and Education-Health: 0.00\n",
      "Business and Applied: 0.00\n",
      "Business and Web: 0.00\n",
      "Business and Sale: 0.02\n"
     ]
    }
   ],
   "source": [
    "for i in range(6, len(dists)): \n",
    "    n1 = 1000\n",
    "    n2 = 1000\n",
    "    p1 = props[5]\n",
    "    p2 = props[i]\n",
    "    p = (n1 * p1 + n2 * p2)/(n1 + n2)\n",
    "    z = (p1 - p2)/(p * (1 - p) * (1/n1 + 1/n2))**0.5\n",
    "    print(\"Business and \" + dists_name[i] + ': {0:0.2f}'.format(\n",
    "      1 - norm.cdf(abs(z))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Education-Health and Applied: 0.01\n",
      "Education-Health and Web: 0.41\n",
      "Education-Health and Sale: 0.00\n"
     ]
    }
   ],
   "source": [
    "for i in range(7, len(dists)): \n",
    "    n1 = 1000\n",
    "    n2 = 1000\n",
    "    p1 = props[6]\n",
    "    p2 = props[i]\n",
    "    p = (n1 * p1 + n2 * p2)/(n1 + n2)\n",
    "    z = (p1 - p2)/(p * (1 - p) * (1/n1 + 1/n2))**0.5\n",
    "    print(\"Education-Health and \" + dists_name[i] + ': {0:0.2f}'.format(\n",
    "      1 - norm.cdf(abs(z))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied and Web: 0.00\n",
      "Applied and Sale: 0.00\n"
     ]
    }
   ],
   "source": [
    "for i in range(8, len(dists)): \n",
    "    n1 = 1000\n",
    "    n2 = 1000\n",
    "    p1 = props[7]\n",
    "    p2 = props[i]\n",
    "    p = (n1 * p1 + n2 * p2)/(n1 + n2)\n",
    "    z = (p1 - p2)/(p * (1 - p) * (1/n1 + 1/n2))**0.5\n",
    "    print(\"Applied and \" + dists_name[i] + ': {0:0.2f}'.format(\n",
    "      1 - norm.cdf(abs(z))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Web and Sale: 0.00\n"
     ]
    }
   ],
   "source": [
    "for i in range(9, len(dists)): \n",
    "    n1 = 1000\n",
    "    n2 = 1000\n",
    "    p1 = props[8]\n",
    "    p2 = props[i]\n",
    "    p = (n1 * p1 + n2 * p2)/(n1 + n2)\n",
    "    z = (p1 - p2)/(p * (1 - p) * (1/n1 + 1/n2))**0.5\n",
    "    print(\"Web and \" + dists_name[i] + ': {0:0.2f}'.format(\n",
    "      1 - norm.cdf(abs(z))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "company[\"fos\"] = company.iloc[:, [17, 18, 19]].sum(axis = 1)\n",
    "company[\"cew\"] = company.iloc[:, [14, 15, 21]].sum(axis = 1)\n",
    "company[\"fb\"] = company.iloc[:, [13, 16]].sum(axis = 1)\n",
    "company = company.drop([\"type_food\", \"type_other\", \"type_sale\", \"type_comm\", \n",
    "                       \"type_edu-health\", \"type_web\", \"type_fin\", \"type_bus\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
